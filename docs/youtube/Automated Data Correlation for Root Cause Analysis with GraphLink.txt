 Hello and welcome to the Observability Trends webinar series. I'm Grant Swanson, your host, and today we will explore the topic of automated data correlation for root cause analysis with GraphLink. We will start with a short overview presentation that highlights this unique feature, followed by a live product demo. Right on the webinar we'll receive an email with a link to the webinar recording. For those interested, we will be conducting a DevOps and SRE observability workshop on May 9th where attendees can get hands-on technical training on how to use log explorer, trace explorer, and metric explorer to troubleshoot real-life scenarios. Now I'd like to introduce our guest speaker, Solutions Engineer, Chris Milton. Thank you, Grant. Hi everyone, welcome to today's webinar. I'm excited to have you join us as we explore fascinating parallels between human cognitive processes and cutting-edge IT observability technology. Today, we'll delve into how our brains manage and interpret vast amounts of data to make decisions, such as Windows, SavelyCross, and Busy Street, and how these principles are mirrored and observes innovative platform with a special focus on its powerful grappling technology. Let's first talk about the intricacies of human data processing. Our brains are continuously overwhelmed with sensory information, and within mere milliseconds our brains integrate this data, enabling us to comprehend and efficiently navigate our surroundings. This remarkable ability to swiftly and precisely connect diverse pieces of data is crucial for our safety and enhances our interactions with the world. Building on our understanding of human data processing, let's explore how these cognitive mechanisms find their counterpart in the realm of IT observability. Within an observed platform, grappling plays a pivotal role akin to the brain's functions in our bodies. It adeptly manages the integration of diverse IT data, such as logs, metrics, and traces, allowing IT professionals to not only gain a comprehensive overview of their systems, but also to quickly troubleshoot issues and make well-informed decisions. This integration is crucial for enhancing system reliability and performance, mirroring how our brains enhance our ability to safely and effectively interact with the world. Throughout our discussion, we'll explore how leveraging advanced data correlation, like that powered by grappling, can significantly reduce troubleshooting times, predict potential system issues, and streamline IT operations. By the end of this webinar, you'll hopefully have a clearer understanding of how essential sophisticated data correlation is, both in human cognition and in managing modern IT infrastructure. So let's dive in and talk about how our brains process information and what lessons we can draw for enhancing IT observability with tools like grappling. So imagine you're about to cross a busy city street, a task that involves processing a tremendous amount of sensory information. Your eyes monitor the traffic, assessing the speed and distance of oncoming cars. Your ears pick up the distinct sounds of engines and horns, which help gauge the flow and urgency of traffic. Simultaneously, your brain integrates this visual and auditory data with spatial information, like the streets whip and your walking speed, calculating whether you have enough time to cross safely. This complex data processing and decision making occur within seconds, showcasing the brain's extraordinary capability to correlate diverse inputs for your safety and efficient navigation of the world around you. This seamless integration of information is managed through neural pathways, which correlate data from your different senses, analyze the risk and guide your actions. This process is incredibly fast and crucial for your safety. Now let's draw an interesting parallel with how observes grappling technology functions within an IT environment. Graphic correlates desperate types of data from various IT sources, logs, metrics, or traces, much like how our brains correlate information from our senses. This technology integrates and visualizes this data to help IT professionals understand the state of their systems, detect anomalies, and troubleshoot with precision. To illustrate this, consider this diagram. This is our data graph view within Observe. Here you see how different data points, representatives' nodes, are linked together much like neural connections in the brain. These links allow IT professionals to quickly trace the root cause of an issue across interconnected systems, similar to how you would assess multiple sensory cues to safely navigate through traffic. And just as our brain's ability to process and correlate information is vital for reacting to our environment, grappling's ability to correlate observability data is crucial for maintaining system health and performance. It enables rapid decision making and problem solving, which are essential in the fast-paced world of technology. In summary, by correlating data as our brain does with sensory inputs, grappling can powers organizations to enhance their operational intelligence, reduce downtime, and optimize performance, ensuring that their IT environments are as safe and efficient as navigating a busy city street as for us. So building an understanding of how the human brain processes complex sensory information to make decisions, lets shift our focus to do a deeper dive into GraphLink, which is a key technology with Observe's IT Observed Ability platform. Like the brain, GraphLink orchestrates the integration and sophisticated correlation of diverse data streams within IT environment, effectively managing and allowing for the analysis of information from multiple sources. So what is GraphLink? Well GraphLink is an advanced component of the Observe platform that functions by linking various types of IT data, such as logs, metrics, and traces. These data types are analogous to the senses in our human brain analogy, each providing critical insights into different aspects of IT system health and performance. Its core functionalities are one, data linking. GraphLink connects data points from different sources by recognizing and utilizing primary and foreign key relationships among the data entities, similar to how databases link tables. This method mirrors how our brain links related sensory inputs to form coherent interpretations of our environment. Two, temporal correlation. GraphLink also correlates data temporally, aligning events and metrics over time to provide a chronological narrative of system activities. This is akin to how our brain processes sequence of events to determine causality in context. Three, visualization. Through dynamic visualizations, GraphLink makes it easy to navigate complex data correlations, enhancing the clarity and speed of troubleshooting efforts. By intelligently correlating diverse data, GraphLink helps pinpoint the origins of issues rapidly. So how does it work? Well, consider a scenario where a server's error rates spikes unexpectedly. Observe and GraphLink technology employs its data correlation capabilities to link this anomaly to related changes captured in deployment logs and performance metrics that occurred around the same time. By establishing relationships based on primary and foreign keys and aligning these events in the temporal context, GraphLink provides a clear, actionable insight into the cause of the spike. GraphLink's ability to correlate data based on relational and temporal dimensions allows IT teams to not only respond to current issues, more effectively, but also to anticipate and mitigate future disruptions. This proactive approach is crucial for maintaining robust, efficient IT operations. In essence, GraphLink equips you with powerful data correlation capabilities to manage and secure your IT environment, much like how our brains help us navigate in and interact safely with the world around us. So now let's take a look at GraphLink and observe an action. What we're looking at here, as described before, is our data set GraphView. Each one of these dots represents a data set coming into the observed platform. This is all the data from our environment coming in. We have AWS, GCP, Kubernetes, as well as contextual data like GitHub, Jenkins, things like that. The lines that you're seeing between these actually show how these data sets correlate with one another. Now a lot of these data correlations have been right out of the box, but if you have a custom application or something like that, you can create these links on your own using the same primary and foreign keys that we discussed earlier. Now let's pivot to our log explorer so we can take a look at how GraphLink might help us troubleshoot an issue. Now move over to logs explorer and we're looking at our container logs. We can see that all of our data is coming in here where we can do all our logs in a single space. I can begin filtering these logs easily on the left side, such as say namespace default. I can filter up here as well by saying I want pods that start with cars or I can begin filtering in here. Like for instance, I'll say show this value only. Now as we're doing this, this is continuing to shape our logs. Using observed schema on demand, I can actually extract data from these log files. I'll go ahead and view this as JSON and I'll extract, say, level as well as message. And it pulls this right into our schema. This applies historically as well as to future state of the logs. We can save these as custom application logs when we have them shaped exactly the way we want. Let's try and visualize this data. We'll go to visualize and we'll say I want to count of values of levels by container and by level. And let's go to a slightly larger data view of four hours. Let's also make this a stacked area chart. Now this view presents us with a lot of noise. We see all of our error messages, or all of our log messages, rather coming in here, debug, error, info and all of those. So let's filter this down a little bit more by saying level contains error. Now we have a much easier view to read that pinpoints where the errors occur at what time and how many. We can easily save this to a dashboard. And I can drag this field across and size it to fit right on my dashboard like that. Now I'll go ahead and save my dashboard. We'll name it. We'll name it. And I'll pivot back to my logs. Now the interesting thing about shaping logs with the visualization is that it continues to do so in your raw logs. So for example, now we can see we have the messages and only level error. Now where graph link comes into play in the log explorer is over here where we can see this text that's in green. Text in green means this is a join data set that they this information does not necessarily appear directly in our logs are the raw container logs that we're looking at. So for example, if I double click on this pod, this is going to give me all the information from this pod's data set view. I can see all of the metadata right here. I can even view metrics as well. The other thing I can do is I can extract fields from this pod's data set and bring those into my container logs. For instance, I'll say add related fields and I'll bring in something like pod restart count. And we can see that now over here. Now the interesting thing about bringing in pod restart count is that is generally infrastructure data and these are app logs so they would normally never appear together. But through leveraging graph link technology, I can pull those all into one log view. I can also double click on this go down to our metrics and say let's look at container CPU usage in seconds, click this to open it in our metrics explorer. Notice it carries over the pod value as well as the time. And this shows us CPU spikes within that pod. Let's go ahead and add this to our dashboard as well. I'll drag this across like before. And here we can actually see something interesting in this dashboard. We're pulling together logs and metrics and we can see how some of these CPU spikes actually correlate with errors that are appeared. I'll go ahead and save these changes. Now let's go ahead and pivot back to our log explorer. As we can see here, we're clearly identifying the error message and the level. So what if we wanted to turn this into a monitor that would generate alerts for us whenever we receive this error message? Well, we could easily go to action and select create monitor. Now I've already created this monitor. So let's go take a look over there by going to monitor. When I go into errors for customers and logs and select view alert, we can actually see how these error messages are affecting our customers. These customers could actually represent servers, different environments or things like that. But the point is it shows us the blast radius of these errors and how it's impacting each customer. Now if I move to the logs for these particular error messages, this brings me into a worksheet. It brings in those error messages already filtered for me while preserving the timestamp. Now I could continue to build out these logs by bringing in additional fields from information we already have in here, such as the items marked in green. But instead, I'm going to leverage graph link down here to actually join this to a completely different data set to see if we can't get to the bottom of these error messages. So I'll click on graph link and I'll say I want to graph link from the linked pods. And I want to link those two our Jenkins builds. Now observe and the way correlation is handled with graph link allows me to pull information in about the build that was pushed specifically to these pods in this time frame. We can see that this build right here was pushed with the commit information of small change to cash code. Now just like before, I can continue to bring in more fields from our Jenkins build. For example, I can say let's add related fields and I'll bring in the GitHub URL. That allows me to do actually something very interesting. I can double click on the URL and that's going to take me right to the GitHub commit page. We're here. We're showing what the change was made. Now that we found the cause of the error, let's turn this into an incident that I can share with my team. By going back into our worksheet here, let's rename some of these fields. I'll say build related to errors. I'm going to call this error logs and I'm going to name this worksheet incident x at y time. And I can go ahead and save this worksheet. I could send this to somebody on my team to triage this further or I could pull this right into our dashboard as well. Now you can see that we have this information in our dashboard as well. Builds relate to errors as well as our error logs. Now that I have this information pulled into the dashboard, I can actually modify these fields as well. I can say, for instance, let's duplicate this list of builds related to errors. And in this duplicate, let's actually go in and turn this into a visualization. So now we're seeing exactly when these builds were pushed. I'll move back to our dashboard. And I will bring this up here and I will pull it over. And here we can see when the build was pushed along with the correlating it with the metrics. So we can see when these CPU spikes were occurring and when the errors in that pod occurred. So using GraphLink and correlating logs, metrics and other information, we can now visualize the entire incident from start to finish as well as the errors that were caused and who was affected. And I'll go ahead and save this dashboard as well. As we conclude today's webinar, let's briefly revisit our exploration of the human brain's data processing abilities and how these concepts apply to the advanced features of Observe's platform, particularly the GraphLink technology. Just as we rely on our senses to write us with real-time data about our environment, allowing us to make quick and form decisions such as when to safely cross a busy street, IT environments also require a sophisticated system to process vast amounts of diverse data. GraphLink serves as a crucial component within Observe, acting as the brain of IT observability by integrating and correlating logs, metrics and traces just as our brain integrates sensory inputs. We discussed how GraphLink links data based on primary and form key relationships, similar to how databases connect tables, and correlates information temporally, providing a detailed, chronological narrative of events. This mirrors the human cognitive process where timing and sequence play critical roles and how we perceive and react to the world around us. GraphLink's capabilities to intelligently correlate diverse data types significantly reduces troubleshooting times, predicts potential system issues and streamlines IT operations. In conclusion, just as our ability to process and correlate sensory data is essential for safely crossing a street, having an advanced observability platform like Observe powered by technologies such as GraphLink is indispensable in the fast-paced world of technology. That ensures IT environments are secure and efficient as our interactions with busy streets, or daily lives, and by embracing technologies that enhance data correlation, organizations can not only maintain but also advance their operational intelligence, ensuring that they are prepared for whatever challenges lie ahead. Thank you for joining today's session. I hope you've left with a deeper appreciation for both the complexity of human cognition and the innovative capabilities of Observe and GraphLink in transforming IT observability. Back to you, Grant. Excellent. Thank you, Chris, for the presentation and demo. The links to our upcoming events and workshop have been posted in the chat window. Everyone who attends the workshop will be given an observability innovator certificate of completion. This concludes our session and thank you for your attention.