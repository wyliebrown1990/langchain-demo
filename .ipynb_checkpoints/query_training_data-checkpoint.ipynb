{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4c3687-482c-4bb9-983d-73cb2efa37f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.1.20)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.11/site-packages (0.0.38)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.6.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.59)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai) (1.30.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.11/site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langchain-community faiss-cpu tiktoken \n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87890d8-fc24-40bb-9fd4-17703cc2ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 13:15:05,511 - INFO - API key loaded successfully\n",
      "2024-05-17 13:15:05,541 - INFO - Found 1 documents\n",
      "2024-05-17 13:15:05,542 - INFO - Loaded 1 documents\n",
      "2024-05-17 13:15:05,586 - INFO - Split documents into 30 chunks\n",
      "2024-05-17 13:15:05,651 - INFO - Creating FAISS library in batches...\n",
      "2024-05-17 13:15:05,651 - INFO - Processing batch 1/1\n",
      "2024-05-17 13:15:06,052 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-17 13:15:06,277 - INFO - Loading faiss.\n",
      "2024-05-17 13:15:06,297 - INFO - Successfully loaded faiss.\n",
      "2024-05-17 13:15:06,350 - INFO - FAISS library created\n",
      "2024-05-17 13:15:06,500 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import gc\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings  # Ensure this import is here\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "#example of prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "#converts the chat model output into a string for convenience\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv_path = os.path.join(os.getcwd(), '.env')\n",
    "if not os.path.exists(dotenv_path):\n",
    "    raise ValueError(f\".env file not found at {dotenv_path}\")\n",
    "\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Verify that the API key is loaded correctly\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please ensure it is set in the .env file.\")\n",
    "else:\n",
    "    logging.info(\"API key loaded successfully\")\n",
    "\n",
    "# Initialize OpenAI LLM\n",
    "llm = OpenAI(api_key=api_key)\n",
    "\n",
    "# Load all text files from the \"training_data\" directory\n",
    "document_paths = glob.glob(\"training_data/*.txt\")\n",
    "documents = []\n",
    "\n",
    "logging.info(f\"Found {len(document_paths)} documents\")\n",
    "\n",
    "for path in document_paths:\n",
    "    loader = TextLoader(path)\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "logging.info(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "logging.info(f\"Split documents into {len(docs)} chunks\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    embedding = OpenAIEmbeddings(api_key=api_key)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing OpenAI embeddings: {e}\")\n",
    "    raise\n",
    "\n",
    "# Proceed with FAISS index creation\n",
    "batch_size = 100\n",
    "batches = [docs[i:i + batch_size] for i in range(0, len(docs), batch_size)]\n",
    "\n",
    "logging.info(\"Creating FAISS library in batches...\")\n",
    "\n",
    "try:\n",
    "    for i, batch in enumerate(batches):\n",
    "        logging.info(f\"Processing batch {i + 1}/{len(batches)}\")\n",
    "        if i == 0:\n",
    "            library = FAISS.from_documents(batch, embedding)\n",
    "        else:\n",
    "            batch_library = FAISS.from_documents(batch, embedding)\n",
    "            library.merge_from(batch_library)\n",
    "        del batch\n",
    "        gc.collect()\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during FAISS library creation: {e}\")\n",
    "    raise\n",
    "\n",
    "logging.info(\"FAISS library created\")\n",
    "\n",
    "# Proceed with similarity search and QA steps incrementally\n",
    "Query1 = \"what makes Observe better than other observability platforms?\"\n",
    "\n",
    "try:\n",
    "    Query_Answer = library.similarity_search(Query1)\n",
    "    logging.info(f\"Query result: {Query_Answer[0].page_content}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during similarity search: {e}\")\n",
    "    raise\n",
    "\n",
    "print(Query_Answer[1].page_content)\n",
    "\n",
    "try:\n",
    "    docs_and_scores = library.similarity_search_with_score(Query1)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during similarity search with score: {e}\")\n",
    "    raise\n",
    "\n",
    "retriever = library.as_retriever()\n",
    "\n",
    "try:\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error creating RetrievalQA: {e}\")\n",
    "    raise\n",
    "\n",
    "retriever_query = \"what is the best Observability feature?\"\n",
    "\n",
    "try:\n",
    "    results = qa.invoke(retriever_query)\n",
    "    logging.info(f\"Results: {results}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during QA invocation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save FAISS index\n",
    "try:\n",
    "    library.save_local(\"faiss_index_observe\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving FAISS index: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    observe_saved = FAISS.load_local(\"faiss_index_observe\", embedding, allow_dangerous_deserialization=True)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading FAISS index: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=observe_saved.as_retriever())\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error creating RetrievalQA with saved index: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    results = qa.invoke(retriever_query)\n",
    "    logging.info(f\"Results after loading FAISS index: {results}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during QA invocation with saved index: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe95b1-dd18-4f48-8d81-d0d11678022a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
